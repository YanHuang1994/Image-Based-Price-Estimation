{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5074b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import math\n",
    "import pyautogui\n",
    "import urllib.parse\n",
    "import time\n",
    "import pyperclip\n",
    "import quopri\n",
    "from bs4 import BeautifulSoup\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import rembg\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, sampler, random_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef117386",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c07cef",
   "metadata": {},
   "source": [
    "#### 1. Download the webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e47c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the operation\n",
    "def auto_download(url,file_name):\n",
    "    pyautogui.hotkey('ctrl', '2') # switch Google Chrome tabs\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    pyautogui.click(207,55) # click the browser's address bar.\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 'a') # select all the content in address bar.\n",
    "    pyperclip.copy(url) # copy the url from pyperclip\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 'v') # paste the url\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    pyautogui.hotkey('enter') # access the url\n",
    "    time.sleep(3)\n",
    "    \n",
    "    pyautogui.click(1910,1020)\n",
    "    pyautogui.mouseDown() # scroll down the page to look through all guitars\n",
    "    time.sleep(30)\n",
    "    pyautogui.mouseUp()# release the left mouse button\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 's') # save the page to local path\n",
    "    time.sleep(2)\n",
    "    \n",
    "    pyperclip.copy(file_name) # copy the file name\n",
    "    pyautogui.hotkey('ctrl', 'v') # paste the file name\n",
    "    time.sleep(2)\n",
    "    \n",
    "    pyautogui.hotkey('enter') # save the page with given name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64cbca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url for guitarcenter\n",
    "base_url = \"https://www.guitarcenter.com/6-String-Acoustic-Guitars.gc?N=1076+18154&Ns=bM&pageName=subcategory-page&recsPerPage=96&profileCountryCode=US&profileCurrencyCode=USD&SPA=true&Nao=\"\n",
    "\n",
    "# create this path in advance for downloading the webpages\n",
    "path = 'guitar_pages'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(path)\n",
    "\n",
    "# download pages\n",
    "def download_pages_guitarcenter(base_url, pages,step):\n",
    "    for i in range(0, pages * step, step):\n",
    "        url = base_url + str(i)\n",
    "        auto_download(url, \"guitar_\" + str(int(i/step)))\n",
    "        time.sleep(5)\n",
    "\n",
    "# actual data\n",
    "# download_pages_guitarcenter(44,96)\n",
    "\n",
    "# use sample data for demonstration\n",
    "download_pages_guitarcenter(base_url, 1, 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3749e63",
   "metadata": {},
   "source": [
    "#### 2. Parse the webpages to read the url of guitar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6539e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the guitarcenter mhtml files\n",
    "def parse_mhtml_guitarcenter(file_path):\n",
    "    # Open the MHTML file in binary mode and parse it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        msg = BytesParser(policy=policy.default).parse(file)\n",
    "\n",
    "    # Decode the HTML part correctly\n",
    "    html_part = None\n",
    "    for part in msg.walk():\n",
    "        content_type = part.get_content_type()\n",
    "        if content_type == 'text/html':\n",
    "            html_part = part.get_payload(decode=True)\n",
    "            break\n",
    "\n",
    "    charset = 'utf-8'\n",
    "    decoded_html = html_part.decode(charset)\n",
    "\n",
    "    # Use BeautifulSoup to parse the decoded HTML\n",
    "    soup = BeautifulSoup(decoded_html, 'html.parser')\n",
    "    \n",
    "    # Get the div with the class of jsx-1611966181 flex flex-auto flex-wrap\n",
    "    div = soup.find(class_=\"jsx-1611966181 flex flex-auto flex-wrap\")\n",
    "\n",
    "    # get the item list from that class\n",
    "    item_list = div.find_all(\"section\",class_=\"plp-product-grid py-[19px] md:p-1.5 flex flex-none flex-col md:flex-row md:border-none border-b border-solid border-[#BBBBBB] w-full md:w-1/2 lg:w-1/3 xl:w-1/4\")\n",
    "    \n",
    "    return item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda96538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the information of item\n",
    "def instru_info_guitarcenter(item_list):\n",
    "    # create a empty dictionary\n",
    "    item_dict = {}\n",
    "\n",
    "    for i in item_list:\n",
    "        # image class\n",
    "        img = i.find(class_ = \"jsx-406435821 w-[264px] mt-5 md:mt-0\")\n",
    "        # title of guitar\n",
    "        title = img.find_all(\"img\")[1][\"alt\"]\n",
    "        # url of guitar image\n",
    "        imgurl = img.find_all(\"img\")[1][\"src\"]\n",
    "        # id for the guitar\n",
    "        item_id = imgurl.split(\"/\")[-1].split(\"-\")[0]\n",
    "        # price of guitar\n",
    "        price = i.find(class_ = \"jsx-2420341498 sale-price gc-font-bold text-[#2d2d2d]\").text\n",
    "        # location of the seller of the guitar\n",
    "        if i.find(class_ = \"jsx-3430979785 store-name-text\"):\n",
    "            location = i.find(class_ = \"jsx-3430979785 store-name-text\").text\n",
    "        else:\n",
    "            location = None\n",
    "        # condition of the guitar\n",
    "        condition = i.find(class_ = \"jsx-3430979785 gc-font-light mb-2 text-xs\").text.replace(\"Condition:\",\"\").strip()\n",
    "        # add the info into dict\n",
    "        item_dict[item_id] = {}\n",
    "        item_dict[item_id]['image'] = imgurl\n",
    "        item_dict[item_id]['title'] = title\n",
    "        item_dict[item_id]['location'] = location\n",
    "        item_dict[item_id]['price'] = price\n",
    "        item_dict[item_id]['condition'] = condition\n",
    "        \n",
    "    return item_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcfb7eb",
   "metadata": {},
   "source": [
    "#### 3. Download the guitar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744bcb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the images\n",
    "def image_download(info,path):\n",
    "    for key,value in info.items():\n",
    "        # download the image that does not exist\n",
    "        if 'image_status' not in info[key]:\n",
    "            # URL of the image\n",
    "            image_url = value['image']\n",
    "            # name of image\n",
    "            file_name = key + \".jpg\"\n",
    "            # the download path\n",
    "            save_path = os.path.join(path, file_name)\n",
    "            # Send a GET request to the image URL\n",
    "            response = requests.get(image_url)\n",
    "\n",
    "            # Check if the request was successful\n",
    "            if response.status_code == 200:\n",
    "                with open(save_path, \"wb\") as file:\n",
    "                    file.write(response.content)\n",
    "                info[key]['image_status'] = 'Success'\n",
    "            \n",
    "            time.sleep(1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a92cd5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "path = 'guitar_pages'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(path)\n",
    "\n",
    "# info of electric guitar\n",
    "guitarcenter_guitar_info = {}\n",
    "\n",
    "# walk through all acoustic guitar files\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        item_list = parse_mhtml_guitarcenter(file_path)\n",
    "        item_dict = instru_info_guitarcenter(item_list)\n",
    "        guitarcenter_guitar_info |= item_dict\n",
    "        \n",
    "# get the url of high-resolution images\n",
    "for key,value in guitarcenter_guitar_info.items():\n",
    "    guitarcenter_guitar_info[key][\"image\"] = guitarcenter_guitar_info[key][\"image\"].replace(\"264x264\",\"600x600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e1e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the high resolution acoustic guitar images\n",
    "count = 0\n",
    "\n",
    "# file path\n",
    "path = 'guitar_images'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(path)\n",
    "\n",
    "while sum([int(bool(value.get(\"image_status\",0))) for key,value in guitarcenter_guitar_info.items()]) < 96:\n",
    "    # handle errors related to unstable internet connection\n",
    "    try:\n",
    "        image_download(guitarcenter_guitar_info,path)\n",
    "    except:\n",
    "        count += 1\n",
    "        print(f\"retry {count}\")\n",
    "        time.sleep(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea54b25",
   "metadata": {},
   "source": [
    "#### 4. Save the info of guitars (id, location, condition, price...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4adae060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dictionary to dataframe \n",
    "df = pd.DataFrame(guitarcenter_guitar_info).T\n",
    "df.to_csv(\"guitar_info.csv\", index=True, index_label=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2b717c",
   "metadata": {},
   "source": [
    "# 2. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95d80bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all necessary functions\n",
    "def widest_boundary(image,left,right,bottom):\n",
    "    # determines the y-coordinate of the widest part of the guitar, which is expected to be within the lower half of the guitar's top section. \n",
    "    # this part is identified by analyzing each horizontal line (row) from the bottom to the top of the image and finding the row with the longest continuous sequence of non-transparent pixels. \n",
    "    # this is done to avoid the influence of any guitar stand in the image by not extending the search to the very bottom.\n",
    "    # the y-coordinate of the row with this longest sequence is considered to be where the guitar is widest, \n",
    "    # which is used as a reference point for further processing such as determining left and right boundaries with reduced impact from the guitar stand.\n",
    "\n",
    "    # initialize the y location and the number of continuous non-transparent pixels\n",
    "    max_num_pixel = 0\n",
    "    y_b = 0\n",
    "    \n",
    "    # iterates over each row\n",
    "    for y in range(bottom):\n",
    "        # extract the pixel sequence\n",
    "        column = [image.getpixel((x, y)) for x in range(left,right)]\n",
    "        \n",
    "        # initialize variables for calculation of the length of continuous non-transparent pixels\n",
    "        num_continous_pixels = []\n",
    "        num_pixel = 0\n",
    "        \n",
    "        # count the length of continuous non-transparent pixels\n",
    "        for pixel in column:\n",
    "            if pixel[3] > 0:\n",
    "                num_pixel += 1\n",
    "            else:\n",
    "                num_continous_pixels.append(num_pixel)\n",
    "                num_pixel = 0\n",
    "        \n",
    "        # find the maximum of length of continuous non-transparent pixels within a row\n",
    "        num_pixel = max(num_continous_pixels)\n",
    "        \n",
    "        # find the maximum of length of continuous non-transparent pixels throughout all rows\n",
    "        if num_pixel >= max_num_pixel:  # Count non-transparent pixels\n",
    "            max_num_pixel = num_pixel\n",
    "            y_b = y\n",
    "\n",
    "    return y_b\n",
    "\n",
    "def left_boundary(image, top, bottom, pixel_count, offset):\n",
    "    # iterate over columns from the left side\n",
    "    for x in range(image.width):\n",
    "        # find the number of non-transparent pixels\n",
    "        column = [image.getpixel((x, y)) for y in range(top, bottom)]\n",
    "        num_pixel = sum(1 for pixel in column if pixel[3] > 0)\n",
    "        \n",
    "        # if the number is more than a threshold then determine the x as the left boundary\n",
    "        if num_pixel >= pixel_count:  # Count non-transparent pixels\n",
    "            left_boundary = x + offset\n",
    "            return left_boundary\n",
    "\n",
    "def right_boundary(image, top, bottom, pixel_count, offset):\n",
    "    # iterate over columns from the right side\n",
    "    for x in range(image.width-1,-1,-1):\n",
    "        # find the number of non-transparent pixels\n",
    "        column = [image.getpixel((x, y)) for y in range(top, bottom)]\n",
    "        num_pixel = sum(1 for pixel in column if pixel[3] > 0)\n",
    "        \n",
    "        # if the number is more than a threshold then determine the x as the right boundary\n",
    "        if num_pixel >= pixel_count:  # Count non-transparent pixels\n",
    "            right_boundary = x - offset\n",
    "            return right_boundary        \n",
    "\n",
    "def bottom_boundary(image, left, right, pixel_count, offset):\n",
    "    # iterate over columns from the bottom\n",
    "    for y in range(image.width-1,-1,-1):\n",
    "        # find the number of non-transparent pixels\n",
    "        column = [image.getpixel((x, y)) for x in range(left,right)]\n",
    "        num_pixel = sum(1 for pixel in column if pixel[3] > 0)\n",
    "        \n",
    "        # if the number is more than a threshold then determine the y as the bottom boundary\n",
    "        if  num_pixel >= pixel_count:  \n",
    "            right_boundary = y - offset\n",
    "            return right_boundary         \n",
    "\n",
    "def top_boundary(image, left, right, bottom, offset):\n",
    "    # iterate over columns from the bottom\n",
    "    for y in range(bottom,-1,-1):\n",
    "        # find the number of non-transparent pixels\n",
    "        column = [image.getpixel((x, y)) for x in range(left,right)]\n",
    "        num_pixel = sum(1 for pixel in column if pixel[3] > 0)\n",
    "        \n",
    "        # if the number is less than a ratio and the width-height ratio is less than 2 determine the y as the top boundary\n",
    "        # this is because we think that the length fingerboard of guitar divided by the length of widest part of guitar should be less than a ratio\n",
    "        # the ratio can vary based on the image, but still be in a range\n",
    "        for ratio in range(31,10,-1):\n",
    "            if num_pixel < ratio / 100 * (right - left) and (bottom - y) < 2 * (right - left):\n",
    "                return y + offset\n",
    "\n",
    "def crop_image(image):\n",
    "    # Convert to RGBA if not already in that mode\n",
    "    if image.mode != 'RGBA':\n",
    "        image = image.convert('RGBA')\n",
    "\n",
    "    # Initialize boundaries\n",
    "    left = 0\n",
    "    top = 0\n",
    "    right = 600\n",
    "    bottom = 600\n",
    "\n",
    "    # find the widest part of the guitar image\n",
    "    widest_y = widest_boundary(image,left,right,bottom)\n",
    "    # find the left boundary of the guitar image\n",
    "    left_b = left_boundary(image, 0, widest_y, 15, 3)\n",
    "    # find the right boundary of the guitar image\n",
    "    right_b = right_boundary(image, 0, widest_y, 15, 3)\n",
    "    # calculate the midpoint of left and right boundary\n",
    "    mid = int((left_b + right_b)/2)\n",
    "    # set an interval centered around the midpoint to search for the bottom boundary\n",
    "    width = 10\n",
    "    # find the bottom boundary of the guitar image\n",
    "    bottom_b = bottom_boundary(image, mid - width, mid + width, 5, 0)\n",
    "    # find the top boundary of the guitar image\n",
    "    top_b = top_boundary(image, left_b, right_b, widest_y, 0)\n",
    "\n",
    "    # crop the image\n",
    "    cropped_image = image.crop((left_b, top_b, right_b, bottom_b))\n",
    "    return cropped_image\n",
    "\n",
    "def resize_pad(image,target_size):\n",
    "    # resize guitar image to square by downsampling and then padding transparently.\n",
    "    # get the width and height from original image\n",
    "    width, height = image.size\n",
    "    \n",
    "    # calculate the scale_ratio\n",
    "    scale_ratio = target_size / height\n",
    "    \n",
    "    # calculate the size after downsampling\n",
    "    new_size =  [math.floor(scale_ratio * width), math.floor(scale_ratio * height)]\n",
    "    \n",
    "    # resize the image\n",
    "    image_resized = image.resize(new_size, Image.LANCZOS)\n",
    "    width_r, height_r = image_resized.size\n",
    "    \n",
    "    # create a transparent background image\n",
    "    new_image = Image.new(\"RGB\", (target_size, target_size), (255, 255, 255))\n",
    "    \n",
    "    # pad the image by pasting the resized image in the middle of background image\n",
    "    upper_x = (target_size - width_r) // 2\n",
    "    upper_y = 0\n",
    "    new_image.paste(image_resized, (upper_x, upper_y),image_resized)\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef24c7c",
   "metadata": {},
   "source": [
    "#### 1. Remove the background of guitar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e48a9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the background of guitar images\n",
    "input_path = \"guitar_images\"\n",
    "output_path = \"guitar_no_background_images\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# walk through all guitar images\n",
    "for root, dirs, files in os.walk(input_path):\n",
    "    for file in files:\n",
    "        input_file_path = os.path.join(root, file)\n",
    "        # Load the input image\n",
    "        input_image = Image.open(input_file_path)\n",
    "        # Convert the input image to a numpy array\n",
    "        input_array = np.array(input_image)\n",
    "\n",
    "        # Apply background removal using rembg\n",
    "        output_array = rembg.remove(input_array)\n",
    "\n",
    "        # Create a PIL Image from the output array\n",
    "        output_image = Image.fromarray(output_array)\n",
    "        \n",
    "        file = file.replace(\"jpg\",\"png\")\n",
    "        output_file_path = os.path.join(output_path, file)\n",
    "        \n",
    "        # Save the output image\n",
    "        output_image.save(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873fc4f",
   "metadata": {},
   "source": [
    "#### 2. Manually remove invalid images (electric guitars, image missing, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16cda36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually eliminated invalid images and save the valid ones to the folder guitar_manually_filtered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b5abe9",
   "metadata": {},
   "source": [
    "#### 3. Crop the images to keep the top soundboard of guitars exclusively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c755f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"guitar_manually_filtered_images\"\n",
    "output_path = \"guitar_cropped_images\"\n",
    "output_path_failed = \"guitar_failed_cropped_images\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "if not os.path.exists(output_path_failed):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(output_path_failed)\n",
    "    \n",
    "# crop the images to keep the top soundboard of guitars exclusively\n",
    "# walk through all guitar images\n",
    "for root, dirs, files in os.walk(input_path):\n",
    "    for file in files:\n",
    "        input_file_path = os.path.join(root, file)\n",
    "        # Load the input image\n",
    "        input_image = Image.open(input_file_path)\n",
    "        # crop the image\n",
    "        try:\n",
    "            output_image = crop_image(input_image)\n",
    "            output_file_path = os.path.join(output_path, file)\n",
    "            # Save the output image\n",
    "            output_image.save(output_file_path)\n",
    "        except:\n",
    "            # if the cropping algorithm fails, save the original image to another path.\n",
    "            output_image = input_image\n",
    "            output_file_path = os.path.join(output_path_failed, file)\n",
    "            # Save the output image\n",
    "            output_image.save(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da537ec6",
   "metadata": {},
   "source": [
    "#### 4. Resize and pad the guitar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a5a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"guitar_cropped_images\"\n",
    "output_path = \"guitar_resized_images\"\n",
    "output_path_failed = \"guitar_failed_resized_images\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "if not os.path.exists(output_path_failed):\n",
    "    # If it does not exist, create it\n",
    "    os.makedirs(output_path_failed)\n",
    "\n",
    "\n",
    "# walk through all guitar images\n",
    "for root, dirs, files in os.walk(input_path):\n",
    "    for file in files:\n",
    "        input_file_path = os.path.join(root, file)\n",
    "        # Load the input image\n",
    "        input_image = Image.open(input_file_path)\n",
    "        target_size = 200\n",
    "        # get the height of image\n",
    "        _, height = input_image.size\n",
    "        \n",
    "        # resize the image which has the height over 200\n",
    "        if height >= 200:\n",
    "            output_image = resize_pad(input_image,target_size)\n",
    "            output_file_path = os.path.join(output_path, file)\n",
    "            # Save the output image\n",
    "            output_image.save(output_file_path)\n",
    "        # for the images that are too small, save them to another path\n",
    "        else:\n",
    "            output_image = input_image\n",
    "            output_file_path = os.path.join(output_path_failed, file)\n",
    "            # Save the output image\n",
    "            output_image.save(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011baac",
   "metadata": {},
   "source": [
    "# 3. Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d02cb0",
   "metadata": {},
   "source": [
    "#### 1. Load the guitar info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f55dd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>price</th>\n",
       "      <th>condition</th>\n",
       "      <th>image_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119781100</td>\n",
       "      <td>https://media.guitarcenter.com/is/image/MMGS7/...</td>\n",
       "      <td>Used Taylor 2011 410CE Acoustic Electric Guitar</td>\n",
       "      <td>Cherry Hill, NJ</td>\n",
       "      <td>1300</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119779356</td>\n",
       "      <td>https://media.guitarcenter.com/is/image/MMGS7/...</td>\n",
       "      <td>Used Ovation 2002 CC57 Celebrity Acoustic Elec...</td>\n",
       "      <td>Round Rock, TX</td>\n",
       "      <td>280</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119776250</td>\n",
       "      <td>https://media.guitarcenter.com/is/image/MMGS7/...</td>\n",
       "      <td>Used Taylor 214CE Deluxe Acoustic Electric Guitar</td>\n",
       "      <td>Jackson, MS</td>\n",
       "      <td>1250</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119776239</td>\n",
       "      <td>https://media.guitarcenter.com/is/image/MMGS7/...</td>\n",
       "      <td>Used Martin D28 Acoustic Guitar</td>\n",
       "      <td>Greensboro, NC</td>\n",
       "      <td>2700</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>119776267</td>\n",
       "      <td>https://media.guitarcenter.com/is/image/MMGS7/...</td>\n",
       "      <td>Used Gretsch Guitars G5024E Rancher Acoustic E...</td>\n",
       "      <td>Goodlettsville, TN</td>\n",
       "      <td>350</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>119749149</td>\n",
       "      <td>https://media.guitarcenter.com/is/image/MMGS7/...</td>\n",
       "      <td>Used Taylor 214CE Deluxe Koa Acoustic Electric...</td>\n",
       "      <td>Johnson City, TN</td>\n",
       "      <td>1200</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>119757084</td>\n",
       "      <td>https://media.guitarcenter.com/is/image/MMGS7/...</td>\n",
       "      <td>Used Taylor Academy 12E Acoustic Electric Guitar</td>\n",
       "      <td>N. Olmsted, OH</td>\n",
       "      <td>600</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>119754997</td>\n",
       "      <td>https://media.guitarcenter.com/is/image/MMGS7/...</td>\n",
       "      <td>Used Taylor 814CE V-Class Acoustic Guitar</td>\n",
       "      <td>Florence, KY</td>\n",
       "      <td>3080</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>119755674</td>\n",
       "      <td>https://media.guitarcenter.com/is/image/MMGS7/...</td>\n",
       "      <td>Used Used Furch Red Pure D-LR Alpine Spruce Na...</td>\n",
       "      <td>Bloomington, MN</td>\n",
       "      <td>2000</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>119745439</td>\n",
       "      <td>https://media.guitarcenter.com/is/image/MMGS7/...</td>\n",
       "      <td>Used Taylor Academy 12 Acoustic Guitar</td>\n",
       "      <td>Ocala, FL</td>\n",
       "      <td>450</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                              image  \\\n",
       "0   119781100  https://media.guitarcenter.com/is/image/MMGS7/...   \n",
       "1   119779356  https://media.guitarcenter.com/is/image/MMGS7/...   \n",
       "3   119776250  https://media.guitarcenter.com/is/image/MMGS7/...   \n",
       "4   119776239  https://media.guitarcenter.com/is/image/MMGS7/...   \n",
       "5   119776267  https://media.guitarcenter.com/is/image/MMGS7/...   \n",
       "..        ...                                                ...   \n",
       "90  119749149  https://media.guitarcenter.com/is/image/MMGS7/...   \n",
       "91  119757084  https://media.guitarcenter.com/is/image/MMGS7/...   \n",
       "92  119754997  https://media.guitarcenter.com/is/image/MMGS7/...   \n",
       "93  119755674  https://media.guitarcenter.com/is/image/MMGS7/...   \n",
       "95  119745439  https://media.guitarcenter.com/is/image/MMGS7/...   \n",
       "\n",
       "                                                title            location  \\\n",
       "0     Used Taylor 2011 410CE Acoustic Electric Guitar     Cherry Hill, NJ   \n",
       "1   Used Ovation 2002 CC57 Celebrity Acoustic Elec...      Round Rock, TX   \n",
       "3   Used Taylor 214CE Deluxe Acoustic Electric Guitar         Jackson, MS   \n",
       "4                     Used Martin D28 Acoustic Guitar      Greensboro, NC   \n",
       "5   Used Gretsch Guitars G5024E Rancher Acoustic E...  Goodlettsville, TN   \n",
       "..                                                ...                 ...   \n",
       "90  Used Taylor 214CE Deluxe Koa Acoustic Electric...    Johnson City, TN   \n",
       "91   Used Taylor Academy 12E Acoustic Electric Guitar      N. Olmsted, OH   \n",
       "92          Used Taylor 814CE V-Class Acoustic Guitar        Florence, KY   \n",
       "93  Used Used Furch Red Pure D-LR Alpine Spruce Na...     Bloomington, MN   \n",
       "95             Used Taylor Academy 12 Acoustic Guitar           Ocala, FL   \n",
       "\n",
       "    price  condition image_status  \n",
       "0    1300  Excellent      Success  \n",
       "1     280  Excellent      Success  \n",
       "3    1250  Excellent      Success  \n",
       "4    2700  Excellent      Success  \n",
       "5     350  Excellent      Success  \n",
       "..    ...        ...          ...  \n",
       "90   1200  Excellent      Success  \n",
       "91    600  Excellent      Success  \n",
       "92   3080  Excellent      Success  \n",
       "93   2000  Excellent      Success  \n",
       "95    450  Excellent      Success  \n",
       "\n",
       "[75 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the guitar info\n",
    "df = pd.read_csv(\"guitar_info.csv\")\n",
    "\n",
    "# load the valid guitar image indice\n",
    "train_data_id = []\n",
    "file_path = \"guitar_resized_images\"\n",
    "\n",
    "# walk through all guitar images\n",
    "for root, dirs, files in os.walk(file_path):\n",
    "    for file in files:\n",
    "        train_data_id.append(int(file.replace(\".png\",\"\")))\n",
    "        \n",
    "# select guitar info for valid images\n",
    "df = df[df['index'].isin(train_data_id)]\n",
    "df['price'] = df['price'].apply(lambda x:math.ceil(float(x.replace(\"$\",\"\").replace(\",\",\"\"))))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744b70d",
   "metadata": {},
   "source": [
    "#### 2. Create training, validation, and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c4c4e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean and std of R, G, and B channels for my guitar image data sets\n",
    "path = \"guitar_resized_images\"\n",
    "\n",
    "# define a tensor transformer\n",
    "image_transformer = T.ToTensor()\n",
    "\n",
    "def normal_para(path, transformer):\n",
    "    tensors = []\n",
    "    # walk through all images and convert them to tensors\n",
    "    for index in df['index'].values:\n",
    "        file_name = '000000'+str(index) + '.png'\n",
    "        file_path = os.path.join(path,file_name)\n",
    "        image = Image.open(file_path)\n",
    "        tensor = transformer(image)\n",
    "        tensors.append(tensor)\n",
    "\n",
    "    # stack all tensors into a single tensor\n",
    "    tensor_stack = torch.stack(tensors, dim=0)\n",
    "\n",
    "    # calculate the mean and std\n",
    "    mean = torch.mean(tensor_stack, dim=[0, 2, 3])\n",
    "    std = torch.std(tensor_stack, dim=[0, 2, 3])\n",
    "    \n",
    "    return mean,std\n",
    "\n",
    "# calculate the mean and std of R, G, and B channels\n",
    "mean,std = normal_para(path, image_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98f77b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a class to generate training, validation, and testing set\n",
    "class Guitar_Image_Data_Set:\n",
    "    \"\"\" this class is designed to generate training, validation, and testing set from guitar images\"\"\"\n",
    "    def __init__(self,dataframe,path,transform):\n",
    "        self.df = dataframe\n",
    "        self.path = path\n",
    "        self.tf = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        file_name = '000000'+ str(df.iloc[idx]['index']) + '.png'\n",
    "        file_path = os.path.join(self.path,file_name)\n",
    "        image = Image.open(file_path)\n",
    "        image = self.tf(image)\n",
    "        price = df.iloc[idx]['price']\n",
    "        \n",
    "        return image, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e191095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform images to tensors and then normalize tensors\n",
    "transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean, std)\n",
    "            ])\n",
    "\n",
    "# create an instance of the Dataset\n",
    "guitar_dataset = Guitar_Image_Data_Set(dataframe = df,\n",
    "                                       path = path,\n",
    "                                       transform = transform)\n",
    "\n",
    "# define the ratio for training, validation, and testing set\n",
    "total = len(guitar_dataset)\n",
    "train = 0.7\n",
    "validation = 0.15\n",
    "\n",
    "# split the whole dataset into training, validation, and testing set\n",
    "train_size = int(train * total)\n",
    "validation_size = int(validation * total)\n",
    "test_size = total - train_size - validation_size\n",
    "train_dataset, validation_dataset, test_dataset = random_split(guitar_dataset, [train_size, validation_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92b73229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DataLoader to batch and shuffle the dataset\n",
    "# actual training, validation, and testing data set\n",
    "# loader_train = DataLoader(train_dataset, batch_size=64,shuffle = True)\n",
    "# loader_val = DataLoader(validation_dataset, batch_size=64,shuffle = True)\n",
    "# loader_test = DataLoader(test_dataset, batch_size=64,shuffle = True)\n",
    "\n",
    "# use smaller batch size for demonstration\n",
    "loader_train = DataLoader(train_dataset, batch_size=4,shuffle = True)\n",
    "loader_val = DataLoader(validation_dataset, batch_size=4,shuffle = True)\n",
    "loader_test = DataLoader(test_dataset, batch_size=4,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b7b93",
   "metadata": {},
   "source": [
    "#### 3. Train baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fc263e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using GPU cuda:0!\n"
     ]
    }
   ],
   "source": [
    "# define the configuration of torch\n",
    "dtype = torch.float\n",
    "\n",
    "gpu_index = torch.randint(0, torch.cuda.device_count(), (1,)).item()\n",
    "device = torch.device('cuda:{}'.format(gpu_index))\n",
    "print(\"PyTorch is using GPU {}!\".format(device))\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad9aa767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that returns a consistent, predetermined random number\n",
    "def fix_random_seed(seed_no=0):\n",
    "    torch.manual_seed(seed_no)\n",
    "    torch.cuda.manual_seed(seed_no)\n",
    "    random.seed(seed_no)\n",
    "\n",
    "# define functions for adjusting learning rate\n",
    "def adjust_learning_rate(optimizer, lrd, epoch, schedule):\n",
    "    \"\"\"\n",
    "    Multiply lrd to the learning rate if epoch is in schedule\n",
    "\n",
    "    Inputs:\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - lrd: learning rate decay; a factor multiplied at scheduled epochs\n",
    "    - epochs: the current epoch number\n",
    "    - schedule: the list of epochs that requires learning rate update\n",
    "\n",
    "    Returns: Nothing, but learning rate might be updated\n",
    "    \"\"\"\n",
    "    if epoch in schedule:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print('lr decay from {} to {}'.format(param_group['lr'], param_group['lr'] * lrd))\n",
    "            param_group['lr'] *= lrd\n",
    "\n",
    "# define functions for training the model\n",
    "def train_model(model, optimizer, epochs=1, learning_rate_decay=.1, schedule=[], criterion = nn.MSELoss()):\n",
    "    \"\"\"\n",
    "    Train a model on guitar image dataset using the PyTorch Module API.\n",
    "\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "\n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_iters = epochs * len(loader_train)\n",
    "    num_prints = num_iters // print_every + 1\n",
    "\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        adjust_learning_rate(optimizer, learning_rate_decay, e, schedule)\n",
    "\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            outputs = model(x)\n",
    "            \n",
    "            # calculatet the loss using assigned criterion \n",
    "            loss = criterion(outputs, y.view(-1, 1))\n",
    "            \n",
    "            # Zero out all of the gradients for the variables which the optimizer will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            tt = t + e * len(loader_train)\n",
    "            print('Epoch %d, Iteration %d, loss = %.0f' % (e, tt, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0c67e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:\n",
      "Sequential(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=120000, out_features=4096, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=4096, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Training:\n",
      "Epoch 0, Iteration 0, loss = 15691427\n",
      "Epoch 0, Iteration 1, loss = 13631764\n",
      "Epoch 0, Iteration 2, loss = 4000830\n",
      "Epoch 0, Iteration 3, loss = 21682328\n",
      "Epoch 0, Iteration 4, loss = 1056676\n",
      "Epoch 0, Iteration 5, loss = 7297549\n",
      "Epoch 0, Iteration 6, loss = 2623719\n",
      "Epoch 0, Iteration 7, loss = 1075998\n",
      "Epoch 0, Iteration 8, loss = 7066142\n",
      "Epoch 0, Iteration 9, loss = 1314058\n",
      "Epoch 0, Iteration 10, loss = 1053513\n",
      "Epoch 0, Iteration 11, loss = 3597074\n",
      "Epoch 0, Iteration 12, loss = 166501\n",
      "Epoch 1, Iteration 13, loss = 1352148\n",
      "Epoch 1, Iteration 14, loss = 7310182\n",
      "Epoch 1, Iteration 15, loss = 915801\n",
      "Epoch 1, Iteration 16, loss = 265838\n",
      "Epoch 1, Iteration 17, loss = 351422\n",
      "Epoch 1, Iteration 18, loss = 351365\n",
      "Epoch 1, Iteration 19, loss = 10167117\n",
      "Epoch 1, Iteration 20, loss = 21163492\n",
      "Epoch 1, Iteration 21, loss = 1258176\n",
      "Epoch 1, Iteration 22, loss = 995471\n",
      "Epoch 1, Iteration 23, loss = 1428170\n",
      "Epoch 1, Iteration 24, loss = 7402848\n",
      "Epoch 1, Iteration 25, loss = 124458\n",
      "Epoch 2, Iteration 26, loss = 871079\n",
      "Epoch 2, Iteration 27, loss = 419193\n",
      "Epoch 2, Iteration 28, loss = 687852\n",
      "Epoch 2, Iteration 29, loss = 927806\n",
      "Epoch 2, Iteration 30, loss = 2938613\n",
      "Epoch 2, Iteration 31, loss = 2612988\n",
      "Epoch 2, Iteration 32, loss = 1349115\n",
      "Epoch 2, Iteration 33, loss = 8595490\n",
      "Epoch 2, Iteration 34, loss = 5135034\n",
      "Epoch 2, Iteration 35, loss = 498536\n",
      "Epoch 2, Iteration 36, loss = 1229023\n",
      "Epoch 2, Iteration 37, loss = 2160740\n",
      "Epoch 2, Iteration 38, loss = 9448333\n",
      "Epoch 3, Iteration 39, loss = 1065003\n",
      "Epoch 3, Iteration 40, loss = 951684\n",
      "Epoch 3, Iteration 41, loss = 2200422\n",
      "Epoch 3, Iteration 42, loss = 5212255\n",
      "Epoch 3, Iteration 43, loss = 9488008\n",
      "Epoch 3, Iteration 44, loss = 5609888\n",
      "Epoch 3, Iteration 45, loss = 1219460\n",
      "Epoch 3, Iteration 46, loss = 5277378\n",
      "Epoch 3, Iteration 47, loss = 313614\n",
      "Epoch 3, Iteration 48, loss = 8663643\n",
      "Epoch 3, Iteration 49, loss = 7845714\n",
      "Epoch 3, Iteration 50, loss = 17035600\n",
      "Epoch 3, Iteration 51, loss = 1105648\n",
      "Epoch 4, Iteration 52, loss = 12523325\n",
      "Epoch 4, Iteration 53, loss = 4334954\n",
      "Epoch 4, Iteration 54, loss = 962772\n",
      "Epoch 4, Iteration 55, loss = 1076556\n",
      "Epoch 4, Iteration 56, loss = 479268\n",
      "Epoch 4, Iteration 57, loss = 394210\n",
      "Epoch 4, Iteration 58, loss = 2344808\n",
      "Epoch 4, Iteration 59, loss = 3452047\n",
      "Epoch 4, Iteration 60, loss = 25132492\n",
      "Epoch 4, Iteration 61, loss = 2119890\n",
      "Epoch 4, Iteration 62, loss = 351740\n",
      "Epoch 4, Iteration 63, loss = 5302476\n",
      "Epoch 4, Iteration 64, loss = 4450448\n"
     ]
    }
   ],
   "source": [
    "# train a toy model - a neural network with two fully connected layers\n",
    "fix_random_seed(0)\n",
    "\n",
    "C, H, W = 3, 200, 200\n",
    "\n",
    "# initialize the output layer with 1 node for regression tasks.\n",
    "output_size = 1 \n",
    "\n",
    "hidden_layer_size = 4096\n",
    "learning_rate = 1e-6\n",
    "weight_decay = 1e-3\n",
    "momentum = 0.5\n",
    "epochs = 5\n",
    "\n",
    "# To give a specific name to each module, use OrderedDict.\n",
    "model = nn.Sequential(OrderedDict([\n",
    "  ('flatten', nn.Flatten()),\n",
    "  ('fc1', nn.Linear(C * H * W, hidden_layer_size)),\n",
    "  ('relu1', nn.ReLU()),\n",
    "  ('fc2', nn.Linear(hidden_layer_size, output_size)),\n",
    "]))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# use SGD as the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=learning_rate,\n",
    "                      weight_decay=weight_decay,\n",
    "                      momentum=momentum,\n",
    "                      nesterov=True)\n",
    "\n",
    "# print the Architecture of the model\n",
    "print('Architecture:')\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# print the loss in the training process\n",
    "print('Training:')\n",
    "train_model(model, optimizer,epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5afbd80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Training:\n",
      "Epoch 0, Iteration 0, loss = 4211798\n",
      "Epoch 0, Iteration 1, loss = 733879\n",
      "Epoch 0, Iteration 2, loss = 926748\n",
      "Epoch 0, Iteration 3, loss = 1043729\n",
      "Epoch 0, Iteration 4, loss = 14631126\n",
      "Epoch 0, Iteration 5, loss = 9693036\n",
      "Epoch 0, Iteration 6, loss = 4349965\n",
      "Epoch 0, Iteration 7, loss = 1238615\n",
      "Epoch 0, Iteration 8, loss = 2217641\n",
      "Epoch 0, Iteration 9, loss = 3963254\n",
      "Epoch 0, Iteration 10, loss = 5138294\n",
      "Epoch 0, Iteration 11, loss = 2817496\n",
      "Epoch 0, Iteration 12, loss = 336634\n",
      "Epoch 1, Iteration 13, loss = 330807\n",
      "Epoch 1, Iteration 14, loss = 1146208\n",
      "Epoch 1, Iteration 15, loss = 4130992\n",
      "Epoch 1, Iteration 16, loss = 4805520\n",
      "Epoch 1, Iteration 17, loss = 5789528\n",
      "Epoch 1, Iteration 18, loss = 7853400\n",
      "Epoch 1, Iteration 19, loss = 87314\n",
      "Epoch 1, Iteration 20, loss = 14163628\n",
      "Epoch 1, Iteration 21, loss = 2355900\n",
      "Epoch 1, Iteration 22, loss = 237990\n",
      "Epoch 1, Iteration 23, loss = 4183016\n",
      "Epoch 1, Iteration 24, loss = 1220696\n",
      "Epoch 1, Iteration 25, loss = 119801\n",
      "Epoch 2, Iteration 26, loss = 851775\n",
      "Epoch 2, Iteration 27, loss = 799002\n",
      "Epoch 2, Iteration 28, loss = 1972055\n",
      "Epoch 2, Iteration 29, loss = 4068858\n",
      "Epoch 2, Iteration 30, loss = 1011048\n",
      "Epoch 2, Iteration 31, loss = 1201487\n",
      "Epoch 2, Iteration 32, loss = 1508468\n",
      "Epoch 2, Iteration 33, loss = 605932\n",
      "Epoch 2, Iteration 34, loss = 3094210\n",
      "Epoch 2, Iteration 35, loss = 472721\n",
      "Epoch 2, Iteration 36, loss = 10470844\n",
      "Epoch 2, Iteration 37, loss = 5987872\n",
      "Epoch 2, Iteration 38, loss = 531165\n",
      "Epoch 3, Iteration 39, loss = 687282\n",
      "Epoch 3, Iteration 40, loss = 813854\n",
      "Epoch 3, Iteration 41, loss = 1840393\n",
      "Epoch 3, Iteration 42, loss = 2134562\n",
      "Epoch 3, Iteration 43, loss = 1142900\n",
      "Epoch 3, Iteration 44, loss = 1334914\n",
      "Epoch 3, Iteration 45, loss = 9107445\n",
      "Epoch 3, Iteration 46, loss = 3648374\n",
      "Epoch 3, Iteration 47, loss = 1931190\n",
      "Epoch 3, Iteration 48, loss = 1281184\n",
      "Epoch 3, Iteration 49, loss = 1536550\n",
      "Epoch 3, Iteration 50, loss = 2246008\n",
      "Epoch 3, Iteration 51, loss = 527458\n",
      "Epoch 4, Iteration 52, loss = 1352025\n",
      "Epoch 4, Iteration 53, loss = 394446\n",
      "Epoch 4, Iteration 54, loss = 3892621\n",
      "Epoch 4, Iteration 55, loss = 2072822\n",
      "Epoch 4, Iteration 56, loss = 1067727\n",
      "Epoch 4, Iteration 57, loss = 2429718\n",
      "Epoch 4, Iteration 58, loss = 956758\n",
      "Epoch 4, Iteration 59, loss = 963024\n",
      "Epoch 4, Iteration 60, loss = 1906030\n",
      "Epoch 4, Iteration 61, loss = 5561908\n",
      "Epoch 4, Iteration 62, loss = 1069943\n",
      "Epoch 4, Iteration 63, loss = 232491\n",
      "Epoch 4, Iteration 64, loss = 1702813\n"
     ]
    }
   ],
   "source": [
    "# train a baseline model - vgg16\n",
    "fix_random_seed(0)\n",
    "\n",
    "C, H, W = 3, 200, 200\n",
    "\n",
    "# initialize the output layer with 1 node for regression tasks.\n",
    "output_size = 1 \n",
    "\n",
    "learning_rate = 1e-4\n",
    "dropout_ratio = 0.1\n",
    "epochs = 5\n",
    "\n",
    "# load the vgg16 model\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# modify the classifier to fit the guitar image dataset\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 512),  \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(dropout_ratio),\n",
    "    nn.Linear(512, 1)  # output a single value for regression\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# use adam as the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr = learning_rate)\n",
    "\n",
    "# print the Architecture of the model\n",
    "print('Architecture:')\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# print the loss in the training process\n",
    "print('Training:')\n",
    "train_model(model, optimizer, epochs = epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
